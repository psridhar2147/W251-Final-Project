# Alexa! What do you See?
* A voice activated automated image captioning system on VizWiz-Captions</i>

* <b>Team:</b> Padmavati Sridhar, Shaji Kunjumohamed, Shwetha Chitta Nagaraj

## Goal:
Design and implement a voice activated image captioning system on the [VizWiz-Captions dataset](https://vizwiz.org/tasks-and-datasets/image-captioning) harnessing the power of Edge and Cloud Computing.

<b>Paper:</b> 
<b>Presentation:</b>

## Abstract:
Using a person’s Alexa device or app, he/she asks Alexa “Alexa! What do you see?” while pointing his/her cellphone to an object or scene that needs captioning.  Alexa then interacts with edge device(Jetson TX2) to get the picture from camera. Jetson then uses an image captioning model trained on the cloud to generate a caption for the picture. Jetson sends the caption text back to Alexa which is then told aloud to the user. 

## Overall Architecture:

![overall_arch](https://github.com/shwethacn/W251-Final-Project/blob/master/imgs/overall_arch.JPG)

## Edge Architecture:

![edge_arch](https://github.com/shwethacn/W251-Final-Project/blob/master/imgs/edge_arch.JPG)

## Dataset:









